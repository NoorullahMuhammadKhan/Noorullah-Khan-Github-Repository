{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8ece24-9e19-4700-97b7-554ba26540f0",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    <strong>All work and rights by Noorullah Khan (47197404) for COMP3420 Artificial Intelligence for Text and Vision, Macquarie University, Session 2, 2024.</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978136a9-3ccd-46d9-8a0b-8520ea380ddc",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 28px; font-weight: bold; color: #4A90E2; margin-bottom: 10px;\">\r\n",
    "    COMP3420 - Artificial Intelligence for Text and Vision\r\n",
    "</p>\r\n",
    "\r\n",
    "<p style=\"text-align: center; font-size: 22px; font-weight: bold; color: #7F8C8D; margin-top: 0; margin-bottom: 20px;\">\r\n",
    "    Assignment 1, Part 2\r\n",
    "</p>\r\n",
    "\r\n",
    "<p style=\"text-align: left; font-size: 24px; font-weight: bold; margin-bottom: 40px;\">\r\n",
    "    Noorullah Khan, 47197404\r\n",
    "</p>\r\n",
    "\r\n",
    "<p style=\"text-align: right; font-size: 22px; font-weight: bold; margin-bottom: 5px;\">\r\n",
    "    Macquarie University,\r\n",
    "</p>\r\n",
    "\r\n",
    "<p style=\"text-align: right; font-size: 22px; font-weight: bold; margin-top: 0;\">\r\n",
    "    Session 2, 2024\r\n",
    "</p>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a906f3-06df-4909-9e54-c033afaba342",
   "metadata": {},
   "source": [
    "#### **Note on Reproducibility and Dynamic Results**\r\n",
    "\r\n",
    "This notebook employs Python code cells to dynamically generate markdown content, particularly for sections that involve displaying the optimal hyperparameters and the model's accuracy results. Due to the inherent randomness in the training process and the hyperparameter tuning using `keras_tuner`, the results, such as the optimal hyperparameters and accuracy percentages, may vary slightly with each run.\r\n",
    "\r\n",
    "To ensure accuracy and consistency, the relevant metrics are directly captured from the model's outputs and automatically inserted into the markdown cells. This approach not only enhances the clarity of the report but also ensures that the most up-to-date and accurate information is presented, reflecting the true performance of the model after each execution.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284695d2-6c0c-4add-b0fd-3eddd678bd29",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 22px; font-weight: bold;\">\n",
    "    Setup & Initialisation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de7e3d-8356-465e-bfc1-98ee406b6b74",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Imports the required Libraries and the build_deep_nn function from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc711a76-46f0-4cca-82e0-e615c950e9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras_tuner as kt\n",
    "import shutil\n",
    "\n",
    "# Importing the build_deep_nn function from a1.py file\n",
    "from a1 import build_deep_nn\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cf1190-6ae6-4cc4-a024-8dfe0ad8c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function build_deep_nn at 0x00000254AE4B7BE0>\n",
      "build_deep_nn function imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Ensuring function was imported successfully\n",
    "print(build_deep_nn)\n",
    "print(\"build_deep_nn function imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789bbc7-e32e-4184-8724-b3d267e0029d",
   "metadata": {},
   "source": [
    "#### Resetting the Tuner\n",
    "Resetting the tuner is to ensure that each hyperparameter search starts fresh, preventing any interference from previous searches, and guaranteeing that the optimal hyperparameters are identified based on the current model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afe85f7-ddd4-4aa3-aeff-4bc4a2c3fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Models Reset\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('tuner_dir', ignore_errors=True)\n",
    "print(\"Previous Models Reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e08ee-38e4-42f5-b9af-1c6836234002",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 24px; font-weight: bold;\">\n",
    "    Loading and Prepare MNIST Dataset\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d13f5a-35d9-4d92-ab26-0267ca7d6007",
   "metadata": {},
   "source": [
    "#### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c00b156-20d3-43a4-90e9-9bf44d63f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28), y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28), y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Step 1b (Part 1): Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Print the shapes to verify the data is loaded correctly\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77019d-dda7-4175-b60a-e2994420cb93",
   "metadata": {},
   "source": [
    "#### Preparing MNIST Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42322ff9-0990-48f5-9ac0-b2f86e925865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1), y_train shape: (60000, 10)\n",
      "x_test shape: (10000, 28, 28, 1), y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the MNIST dataset for training\n",
    "\n",
    "# Reshape the data to add the channel dimension (since MNIST images are grayscale)\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Convert the labels to categorical format (one-hot encoding for 10 classes)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Print the shapes to verify everything is correct after preparation\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf3690-5381-4112-8692-212e32443696",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 24px; font-weight: bold;\">\n",
    "    Hyperparameter Search\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff23c6-3ab6-4af0-9805-f46133f376c4",
   "metadata": {},
   "source": [
    "#### Define the Model Builder Function for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd82e45-475a-47ec-9de1-9939db43306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    # Define the hyperparameters to search for\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=3)\n",
    "    layer_size = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    dropout_rate = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "\n",
    "    # Create the layer options for build_deep_nn\n",
    "    print(f\"Building layer options with num_layers={num_layers}, layer_size={layer_size}, dropout_rate={dropout_rate}\")\n",
    "    layer_options = [(layer_size, 'relu', 0.0) for _ in range(num_layers - 1)]\n",
    "    layer_options.append((layer_size, 'relu', dropout_rate))\n",
    "\n",
    "    # Build the model using the build_deep_nn function\n",
    "    model = build_deep_nn(28, 28, 1, layer_options)\n",
    "\n",
    "    # Print the model summary\n",
    "    print(\"Model Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282df59-4a04-4f25-90f5-27fe5811be25",
   "metadata": {},
   "source": [
    "#### Set Up Keras Tuner for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb03e8d-afe1-4932-bab9-5ed865e383c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the tuner...\n",
      "Building layer options with num_layers=1, layer_size=32, dropout_rate=0.0\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Compiling model...\n",
      "Tuner set up successfully. Ready to start hyperparameter search.\n"
     ]
    }
   ],
   "source": [
    "# Set up the tuner\n",
    "print(\"Setting up the tuner...\")\n",
    "tuner = kt.RandomSearch(\n",
    "    model_builder,                   # Pass the model builder function\n",
    "    objective='val_accuracy',        # Objective to optimize (validation accuracy)\n",
    "    max_trials=10,                   # Number of different hyperparameter combinations to try\n",
    "    directory='tuner_dir',           # Directory to save tuner results\n",
    "    project_name='mnist_tuning'      # Name of the project\n",
    ")\n",
    "\n",
    "print(\"Tuner set up successfully. Ready to start hyperparameter search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85a82d-c314-4a8e-8861-035e0bcef3d1",
   "metadata": {},
   "source": [
    "#### Run the Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4b8aee-5bec-435a-993e-77cfaa7a0f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 27s]\n",
      "val_accuracy: 0.980400025844574\n",
      "\n",
      "Best val_accuracy So Far: 0.9818000197410583\n",
      "Total elapsed time: 00h 04m 23s\n",
      "Hyperparameter search completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter search\n",
    "print(\"Starting hyperparameter search...\")\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "print(\"Hyperparameter search completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83bc3e6-ac56-4394-9ed3-c2215c3af3dd",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 22px; font-weight: bold;\">\r\n",
    "   Model Optimisationn\r\n",
    "</p>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea116b0-491a-4cfd-a0c2-a788fcf7b998",
   "metadata": {},
   "source": [
    "#### Extract the Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22957f49-97af-40ab-ac48-30a5f7c0b126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal hyperparameters found:\n",
      "Best number of layers: 1\n",
      "Best layer size: 416\n",
      "Best dropout rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Optimal hyperparameters found:\")\n",
    "print(f\"Best number of layers: {best_hps.get('num_layers')}\")\n",
    "print(f\"Best layer size: {best_hps.get('units')}\")\n",
    "print(f\"Best dropout rate: {best_hps.get('dropout')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd515b-a5e0-41a8-bb7e-c27bed249ba9",
   "metadata": {},
   "source": [
    "#### Build the Model with Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7477656-0fac-4ef9-bfd6-4192c1071932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built and compiled successfully with optimal hyperparameters.\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters\n",
    "optimal_layers = [(best_hps.get('units'), 'relu', 0.0) for _ in range(best_hps.get('num_layers') - 1)] + \\\n",
    "                 [(best_hps.get('units'), 'relu', best_hps.get('dropout'))]\n",
    "\n",
    "model = build_deep_nn(28, 28, 1, optimal_layers)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Model built and compiled successfully with optimal hyperparameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cf319-07bf-4d40-b5bc-9a6cef077431",
   "metadata": {},
   "source": [
    "#### Train the Model with Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214ffd3e-0434-4f6e-8071-787e2f2343fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2062 - accuracy: 0.9398 - val_loss: 0.1161 - val_accuracy: 0.9645\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0842 - accuracy: 0.9748 - val_loss: 0.0804 - val_accuracy: 0.9744\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 0.0689 - val_accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.0570 - val_accuracy: 0.9814\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedff38b-283f-4a6c-b772-8476becee1af",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 22px; font-weight: bold;\">\n",
    "    Conclusion\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee515d-cda9-4407-9895-809e8b5a01f1",
   "metadata": {},
   "source": [
    "#### Evaluating the Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cbc930-2e1e-402a-adca-90ca076f81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9806\n",
      "Test accuracy: 0.9805999994277954\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "# Print the test accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ce7c1e2-6124-4127-a6ae-280217a0c27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Evaluating the Model:**\n",
       "\n",
       "The model was evaluated on the test set, and the following results were obtained:\n",
       "\n",
       "- **Test Loss:** `0.0679`  \n",
       "  The loss metric indicates how well the model's predictions align with the actual labels. A lower loss generally implies better model performance. In this case, the model's test loss of `0.0679` suggests that it has learned to generalize well to unseen data.\n",
       "\n",
       "- **Test Accuracy:** `0.9806`  \n",
       "  The test accuracy of `0.9806` (or `98.06%`) indicates that the model correctly classified approximately `98.06%` of the images in the test set. This high accuracy reflects the model's effectiveness in recognizing and classifying the digits from the MNIST dataset with a high level of precision.\n",
       "\n",
       "Overall, these results demonstrate that the model is performing exceptionally well.** Achieving a test accuracy close to 98% on the MNIST dataset is considered very good, indicating that the model has successfully learned to identify the digits with high accuracy.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the results in markdown format\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**Evaluating the Model:**\n",
    "\n",
    "The model was evaluated on the test set, and the following results were obtained:\n",
    "\n",
    "- **Test Loss:** `{test_loss:.4f}`  \n",
    "  The loss metric indicates how well the model's predictions align with the actual labels. A lower loss generally implies better model performance. In this case, the model's test loss of `{test_loss:.4f}` suggests that it has learned to generalize well to unseen data.\n",
    "\n",
    "- **Test Accuracy:** `{test_accuracy:.4f}`  \n",
    "  The test accuracy of `{test_accuracy:.4f}` (or `{test_accuracy*100:.2f}%`) indicates that the model correctly classified approximately `{test_accuracy*100:.2f}%` of the images in the test set. This high accuracy reflects the model's effectiveness in recognizing and classifying the digits from the MNIST dataset with a high level of precision.\n",
    "\n",
    "Overall, these results demonstrate that the model is performing exceptionally well.** Achieving a test accuracy close to 98% on the MNIST dataset is considered very good, indicating that the model has successfully learned to identify the digits with high accuracy.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59595adc-9427-49c2-8141-ef4fedee876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### **Hyperparameters of the Optimal Model**\n",
       "\n",
       "The optimal hyperparameters for the model, as determined by `keras_tuner`, are:\n",
       "\n",
       "- **Number of hidden layers:** `1`\n",
       "- **Size of the hidden layer:** `416 units`\n",
       "- **Dropout rate of the final hidden layer:** `0.0`\n",
       "\n",
       "These hyperparameters were found to yield the highest validation accuracy during the tuning process.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dynamically inserting the optimal hyperparameters into the markdown\n",
    "best_layers = best_hps.get('num_layers')\n",
    "best_units = best_hps.get('units')\n",
    "best_dropout = best_hps.get('dropout')\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "#### **Hyperparameters of the Optimal Model**\n",
    "\n",
    "The optimal hyperparameters for the model, as determined by `keras_tuner`, are:\n",
    "\n",
    "- **Number of hidden layers:** `{best_layers}`\n",
    "- **Size of the hidden layer:** `{best_units} units`\n",
    "- **Dropout rate of the final hidden layer:** `{best_dropout}`\n",
    "\n",
    "These hyperparameters were found to yield the highest validation accuracy during the tuning process.\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26c56e6e-034f-46f0-85b0-e6db6b32d8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### **Accuracy Results of the Optimal Model**\n",
       "\n",
       "After training the model with the optimal hyperparameters, the model was evaluated on the test set. The accuracy results are as follows:\n",
       "\n",
       "- **Test set accuracy:** `98.06%` (`0.9806`)\n",
       "\n",
       "This indicates that the model correctly classified `98.06%` of the images in the test set, demonstrating its effectiveness at recognizing handwritten digits from the MNIST dataset.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After running the model training and evaluation, you can insert the accuracy results dynamically\n",
    "test_accuracy_percent = test_accuracy * 100\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "#### **Accuracy Results of the Optimal Model**\n",
    "\n",
    "After training the model with the optimal hyperparameters, the model was evaluated on the test set. The accuracy results are as follows:\n",
    "\n",
    "- **Test set accuracy:** `{test_accuracy_percent:.2f}%` (`{test_accuracy:.4f}`)\n",
    "\n",
    "This indicates that the model correctly classified `{test_accuracy_percent:.2f}%` of the images in the test set, demonstrating its effectiveness at recognizing handwritten digits from the MNIST dataset.\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e701b-62e4-4028-8213-bd57356b5dfe",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\r\n",
    "    <strong>All work and rights by Noorullah Khan (47197404) for COMP3420 Artificial Intelligence for Text and Vision, Macquarie University, Session 2, 2024.</strong>\r\n",
    "</p>\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMP3420)",
   "language": "python",
   "name": "comp3420"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
